{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65f1406",
   "metadata": {
    "papermill": {
     "duration": 0.005704,
     "end_time": "2025-03-30T22:02:19.867086",
     "exception": false,
     "start_time": "2025-03-30T22:02:19.861382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3d665c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:02:25.607964Z",
     "iopub.status.busy": "2025-03-30T22:02:25.607484Z",
     "iopub.status.idle": "2025-03-30T22:02:43.750273Z",
     "shell.execute_reply": "2025-03-30T22:02:43.748928Z"
    },
    "papermill": {
     "duration": 18.154578,
     "end_time": "2025-03-30T22:02:43.752339",
     "exception": false,
     "start_time": "2025-03-30T22:02:25.597761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.signal import resample\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3544d31f",
   "metadata": {
    "papermill": {
     "duration": 0.005495,
     "end_time": "2025-03-30T22:02:43.764003",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.758508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions\n",
    "## map_labels\n",
    "This function can be used to simplify the labels. With a given label dictionary, we can map the labels to a less specific label."
   ]
  },
  {
   "cell_type": "code",
   "id": "71ee52a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:02:43.776882Z",
     "iopub.status.busy": "2025-03-30T22:02:43.776197Z",
     "iopub.status.idle": "2025-03-30T22:02:43.781818Z",
     "shell.execute_reply": "2025-03-30T22:02:43.780811Z"
    },
    "papermill": {
     "duration": 0.014315,
     "end_time": "2025-03-30T22:02:43.783782",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.769467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "def map_labels(data, label_dict, label_mapping):\n",
    "    \"\"\"\n",
    "    Maps annotations in a dataset to their corresponding labels using a given mapping.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): A DataFrame containing an 'annotation' column with values to be mapped.\n",
    "        label_dict (dict): A dictionary containing mappings of annotation labels.\n",
    "                                Keys are label mapping names, and values are Pandas Series or DataFrames\n",
    "                                where the index represents annotation keys and values represent labels.\n",
    "        label_mapping (str): The key in `anno_label_dict` corresponding to the desired label mapping.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The input DataFrame with an added or updated 'label' column containing the mapped labels.\n",
    "    \"\"\"\n",
    "    data['label'] = (label_dict[label_mapping].reindex(data['annotation']).to_numpy())\n",
    "    return data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "188fb41a",
   "metadata": {
    "papermill": {
     "duration": 0.005229,
     "end_time": "2025-03-30T22:02:43.794722",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.789493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## normalize\n",
    "Normalize the data to make it better for generalization"
   ]
  },
  {
   "cell_type": "code",
   "id": "27c83fe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:02:43.806983Z",
     "iopub.status.busy": "2025-03-30T22:02:43.806608Z",
     "iopub.status.idle": "2025-03-30T22:02:43.811553Z",
     "shell.execute_reply": "2025-03-30T22:02:43.810584Z"
    },
    "papermill": {
     "duration": 0.013389,
     "end_time": "2025-03-30T22:02:43.813484",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.800095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "def normalize(data, feature_cols):\n",
    "    \"\"\"\n",
    "    Normalizes the specified feature columns of a DataFrame using Min-Max scaling.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): A DataFrame containing the features to be normalized.\n",
    "        feature_cols (list of str): List of column names in `data` to normalize.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with the specified columns normalized to the range [0, 1].\n",
    "        The original `data` DataFrame is modified in place.\n",
    "        \n",
    "    Notes:\n",
    "        - Min-Max normalization scales each feature column to the range [0, 1] based on \n",
    "          the minimum and maximum values of the column.\n",
    "        - This transformation is often used to prepare data for machine learning models \n",
    "          that are sensitive to feature magnitudes.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    data[feature_cols] = scaler.fit_transform(data[feature_cols])\n",
    "    return data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "877b6ae5",
   "metadata": {
    "papermill": {
     "duration": 0.005292,
     "end_time": "2025-03-30T22:02:43.824565",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.819273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## calculate_window_purity"
   ]
  },
  {
   "cell_type": "code",
   "id": "0b777a75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:02:43.836923Z",
     "iopub.status.busy": "2025-03-30T22:02:43.836540Z",
     "iopub.status.idle": "2025-03-30T22:02:43.841524Z",
     "shell.execute_reply": "2025-03-30T22:02:43.840477Z"
    },
    "papermill": {
     "duration": 0.013282,
     "end_time": "2025-03-30T22:02:43.843377",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.830095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "def calculate_window_purity(window_labels):\n",
    "    \"\"\"\n",
    "    Calculates the purity of a label window based on the proportion of the most frequent label.\n",
    "\n",
    "    Args:\n",
    "        window_labels (pd.Series or np.ndarray): Labels in a time window.\n",
    "\n",
    "    Returns:\n",
    "        float: Purity score between 0 and 1. Higher means purer (more consistent label).\n",
    "    \"\"\"\n",
    "    if len(window_labels) == 0:\n",
    "        return 0.0\n",
    "    counts = pd.Series(window_labels).value_counts()\n",
    "    return counts.iloc[0] / len(window_labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d3bbe137",
   "metadata": {
    "papermill": {
     "duration": 0.005832,
     "end_time": "2025-03-30T22:02:43.854894",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.849062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## extract_windows\n",
    "A function to create windows. We can also change the frequency of the windows by downsampling."
   ]
  },
  {
   "cell_type": "code",
   "id": "e5d3548c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:02:43.867420Z",
     "iopub.status.busy": "2025-03-30T22:02:43.867080Z",
     "iopub.status.idle": "2025-03-30T22:02:43.874996Z",
     "shell.execute_reply": "2025-03-30T22:02:43.873892Z"
    },
    "papermill": {
     "duration": 0.016265,
     "end_time": "2025-03-30T22:02:43.876727",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.860462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "def extract_windows(data, winsize=90, input_frequency=100, output_frequency=64):\n",
    "    \"\"\"\n",
    "    Extracts sliding windows from time series data and labels for classification tasks.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Time series DataFrame with 'x', 'y', 'z' (accelerometer data) and 'label'.\n",
    "                             Index should be a datetime-like index.\n",
    "        winsize (int): Window size in seconds.\n",
    "        input_frequency (int): Sampling frequency of input data in Hz.\n",
    "        output_frequency (int): Desired output frequency in Hz (must be a divisor of input_frequency).\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): Shape (n_samples, output_samples, 3), accelerometer windows.\n",
    "        Y (np.ndarray): Shape (n_samples,), most frequent label per window.\n",
    "    \"\"\"\n",
    "    # Calculate window size in samples and target output samples\n",
    "    window_samples = winsize * input_frequency\n",
    "    output_samples = winsize * output_frequency  # Expected downsampled length\n",
    "\n",
    "    X, Y = [], []\n",
    "    purities = []\n",
    "\n",
    "    # Sliding window extraction\n",
    "    for start in range(0, len(data) - window_samples + 1, window_samples):\n",
    "        window = data.iloc[start:start + window_samples]\n",
    "\n",
    "        # Skip if missing values exist\n",
    "        if window.isna().any().any() or len(window) != window_samples:\n",
    "            continue\n",
    "\n",
    "        # Extract and resample accelerometer data\n",
    "        x = window[['x', 'y', 'z']].to_numpy()\n",
    "        x = resample(x, output_samples)  # Resample to match output frequency\n",
    "\n",
    "        # Extract the most frequent label (mode)\n",
    "        y = window['label'].mode().iloc[0]\n",
    "\n",
    "        purity = calculate_window_purity(window['label'])\n",
    "\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        purities.append(purity)\n",
    "\n",
    "    X = np.stack(X) if X else np.empty((0, output_samples, 3))\n",
    "    Y = np.array(Y) if Y else np.empty((0,))\n",
    "\n",
    "    return X, Y, purities"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35e8325b",
   "metadata": {
    "papermill": {
     "duration": 0.005415,
     "end_time": "2025-03-30T22:02:43.887784",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.882369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Print input files"
   ]
  },
  {
   "cell_type": "code",
   "id": "63ae34fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:02:43.900055Z",
     "iopub.status.busy": "2025-03-30T22:02:43.899673Z",
     "iopub.status.idle": "2025-03-30T22:02:43.941890Z",
     "shell.execute_reply": "2025-03-30T22:02:43.940801Z"
    },
    "papermill": {
     "duration": 0.050469,
     "end_time": "2025-03-30T22:02:43.943741",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.893272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dictionary of labels\n",
    "label_dict = pd.read_csv('/kaggle/input/capture-24-human-activity-recognition/capture24/annotation-label-dictionary.csv', index_col='annotation', dtype='string')\n",
    "\n",
    "# Chosen label mapping\n",
    "label_mapping = \"label:Willetts2018\"\n",
    "print(label_dict[label_mapping])\n",
    "print()\n",
    "\n",
    "# Print files\n",
    "print('Content of data/')\n",
    "print(sorted(os.listdir('/kaggle/input/capture-24-human-activity-recognition/capture24')))\n",
    "print()\n",
    "\n",
    "# All of the labels\n",
    "all_labels = list({*label_dict[label_mapping]})\n",
    "print('All of the possible labels:')\n",
    "print(all_labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b1a0abec",
   "metadata": {
    "papermill": {
     "duration": 0.005393,
     "end_time": "2025-03-30T22:02:43.955064",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.949671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the model\n",
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "77afd4ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:02:43.967518Z",
     "iopub.status.busy": "2025-03-30T22:02:43.967163Z",
     "iopub.status.idle": "2025-03-30T22:02:43.975144Z",
     "shell.execute_reply": "2025-03-30T22:02:43.974130Z"
    },
    "papermill": {
     "duration": 0.015974,
     "end_time": "2025-03-30T22:02:43.976552",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.960578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Path of the dataset\n",
    "path = '/kaggle/input/capture-24-human-activity-recognition/capture24/'\n",
    "\n",
    "# The files in the dataset\n",
    "file_list = sorted([f for f in os.listdir(path) if f.endswith('.csv') and f.startswith('P')])\n",
    "\n",
    "# Data and window parameters\n",
    "winsize = 90\n",
    "num_train_files = 100\n",
    "num_test_files = 51\n",
    "frequency = 64\n",
    "\n",
    "if num_train_files + num_test_files > 151:\n",
    "    raise Exception(\"Number of training and testing files exceeds the total number of files.\")\n",
    "\n",
    "# Choose test files\n",
    "test_files = file_list[-num_test_files:]\n",
    "\n",
    "# Choose train files\n",
    "train_files = file_list[:num_train_files]\n",
    "\n",
    "num_train_files = len(train_files)\n",
    "num_test_files = len(test_files)\n",
    "\n",
    "print(\"Number of files used for training:\", num_train_files)\n",
    "print(\"Number of files used for testing:\", num_test_files)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44d8f4c0",
   "metadata": {
    "papermill": {
     "duration": 0.005553,
     "end_time": "2025-03-30T22:02:43.988009",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.982456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training set"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc05d5d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T22:02:44.000565Z",
     "iopub.status.busy": "2025-03-30T22:02:44.000219Z",
     "iopub.status.idle": "2025-03-30T23:01:59.224820Z",
     "shell.execute_reply": "2025-03-30T23:01:59.223510Z"
    },
    "papermill": {
     "duration": 3555.233038,
     "end_time": "2025-03-30T23:01:59.226666",
     "exception": false,
     "start_time": "2025-03-30T22:02:43.993628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "file_id = 0\n",
    "\n",
    "Y_train = []\n",
    "\n",
    "# Loop through the training files\n",
    "for file in train_files:    \n",
    "    print(f\"Processing file {file_id + 1}\")\n",
    "    file_id = file_id + 1\n",
    "\n",
    "    file_path = os.path.join(path, file)\n",
    "    file_path = os.path.join(file_path, file)\n",
    "\n",
    "    data = pd.read_csv(file_path, index_col='time', parse_dates=['time'],\n",
    "                           dtype={'x': 'f4', 'y': 'f4', 'z': 'f4', 'annotation': 'string'})\n",
    "\n",
    "    data = map_labels(data, label_dict, label_mapping)      \n",
    "    data = normalize(data, ['x','y','z'])\n",
    "    \n",
    "    # Extract windows and labels\n",
    "    _, Y_, purities = extract_windows(data)\n",
    "    Y_train.append(Y_)\n",
    "    \n",
    "    # Print the average purity of the windows\n",
    "    print(sum(purities) / len(purities) if purities else 0)\n",
    "    gc.collect()\n",
    "\n",
    "# Concatenate the labels\n",
    "Y_train = np.concatenate(Y_train, axis=0)\n",
    "\n",
    "# Count the labels\n",
    "label_counts = Counter(Y_train)\n",
    "\n",
    "# Ensure all labels are present (even with 0)\n",
    "label_series = pd.Series({label: label_counts.get(label, 0) for label in all_labels})\n",
    "\n",
    "# Normalize to get percentages\n",
    "label_series = label_series / label_series.sum()\n",
    "\n",
    "# Set a clean style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create figure and axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=label_series.index, y=label_series.values, palette='tab10')\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(\"Label Distribution in the Training Set\", fontsize=16, weight='bold')\n",
    "plt.xlabel(\"Activity Label\", fontsize=12)\n",
    "plt.ylabel(\"Percentage\", fontsize=12)\n",
    "\n",
    "# Rotate x-axis labels and style\n",
    "plt.xticks(rotation=30, ha='right', fontsize=11)\n",
    "\n",
    "# Annotate each bar with the percentage\n",
    "for i, v in enumerate(label_series.values):\n",
    "    ax.text(i, v + 0.01, f\"{v:.2f}\", ha='center', va='bottom', fontsize=10, weight='bold')\n",
    "\n",
    "plt.ylim(0, max(label_series.values) + 0.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2873b082",
   "metadata": {
    "papermill": {
     "duration": 0.011599,
     "end_time": "2025-03-30T23:01:59.251149",
     "exception": false,
     "start_time": "2025-03-30T23:01:59.239550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing set"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3332c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:01:59.276424Z",
     "iopub.status.busy": "2025-03-30T23:01:59.276051Z",
     "iopub.status.idle": "2025-03-30T23:33:14.300472Z",
     "shell.execute_reply": "2025-03-30T23:33:14.299260Z"
    },
    "papermill": {
     "duration": 1875.040168,
     "end_time": "2025-03-30T23:33:14.303196",
     "exception": false,
     "start_time": "2025-03-30T23:01:59.263028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "file_id = 0\n",
    "\n",
    "Y_test = []\n",
    "\n",
    "# Loop through the testing files\n",
    "for file in test_files:    \n",
    "    print(f\"Processing file {file_id + 1}\")\n",
    "    file_id = file_id + 1\n",
    "\n",
    "    file_path = os.path.join(path, file)\n",
    "    file_path = os.path.join(file_path, file)\n",
    "    data = pd.read_csv(file_path, index_col='time', parse_dates=['time'],\n",
    "                           dtype={'x': 'f4', 'y': 'f4', 'z': 'f4', 'annotation': 'string'})\n",
    "\n",
    "    data = map_labels(data, label_dict, label_mapping)      \n",
    "    data = normalize(data, ['x','y','z'])\n",
    "    \n",
    "    # Extract windows and labels\n",
    "    _, Y_, purities = extract_windows(data)\n",
    "    Y_test.append(Y_)\n",
    "    \n",
    "    # Print the average purity of the windows\n",
    "    print(sum(purities) / len(purities) if purities else 0)\n",
    "    gc.collect()\n",
    "\n",
    "# Concatenate the labels\n",
    "Y_test = np.concatenate(Y_test, axis=0)\n",
    "\n",
    "# Count the labels\n",
    "label_counts = Counter(Y_test)\n",
    "\n",
    "# Ensure all labels are included and ordered like in all_labels\n",
    "label_series = pd.Series({label: label_counts.get(label, 0) for label in all_labels})\n",
    "\n",
    "# Normalize to percentages\n",
    "label_series = label_series / label_series.sum()\n",
    "\n",
    "# Set a clean style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create figure and axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=label_series.index, y=label_series.values, palette='tab10')\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(\"Label Distribution in the Testing Set\", fontsize=16, weight='bold')\n",
    "plt.xlabel(\"Activity Label\", fontsize=12)\n",
    "plt.ylabel(\"Percentage\", fontsize=12)\n",
    "\n",
    "# Rotate x-axis labels and style\n",
    "plt.xticks(rotation=30, ha='right', fontsize=11)\n",
    "\n",
    "for i, v in enumerate(label_series.values):\n",
    "    ax.text(i, v + 0.01, f\"{v:.2f}\", ha='center', va='bottom', fontsize=10, weight='bold')\n",
    "\n",
    "plt.ylim(0, max(label_series.values) + 0.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "21ffcace",
   "metadata": {
    "papermill": {
     "duration": 0.015528,
     "end_time": "2025-03-30T23:33:14.335921",
     "exception": false,
     "start_time": "2025-03-30T23:33:14.320393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Purity per file"
   ]
  },
  {
   "cell_type": "code",
   "id": "19e8f109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T23:33:14.369119Z",
     "iopub.status.busy": "2025-03-30T23:33:14.368761Z",
     "iopub.status.idle": "2025-03-31T01:01:47.366211Z",
     "shell.execute_reply": "2025-03-31T01:01:47.363225Z"
    },
    "papermill": {
     "duration": 5313.08216,
     "end_time": "2025-03-31T01:01:47.433879",
     "exception": false,
     "start_time": "2025-03-30T23:33:14.351719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "file_purities = []\n",
    "\n",
    "# Loop through the files\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(path, file)\n",
    "    file_path = os.path.join(file_path, file)\n",
    "    \n",
    "    data = pd.read_csv(file_path, index_col='time', parse_dates=['time'],\n",
    "                       dtype={'x': 'f4', 'y': 'f4', 'z': 'f4', 'annotation': 'string'})\n",
    "\n",
    "    data = map_labels(data, label_dict, label_mapping)\n",
    "    data = normalize(data, ['x', 'y', 'z'])\n",
    "    \n",
    "    # Extract windows and labels\n",
    "    _, labels, purities = extract_windows(data)\n",
    "    purity = sum(purities) / len(purities) if purities else 0\n",
    "    \n",
    "    # Append the file name and purity\n",
    "    file_name = os.path.basename(file)\n",
    "    file_purities.append((file_name, purity))\n",
    "\n",
    "# Create a DataFrame and sort by file name\n",
    "purity_df = pd.DataFrame(file_purities, columns=[\"File\", \"Average Window Purity\"])\n",
    "purity_df = purity_df.sort_values(\"File\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(22, 6))  # Wider figure for breathing room\n",
    "bars = ax.bar(purity_df[\"File\"], purity_df[\"Average Window Purity\"], color='steelblue', edgecolor='black', linewidth=0.4)\n",
    "\n",
    "# Titles and labels\n",
    "ax.set_title(\"Average Window Purity per File\", fontsize=18, weight='bold', pad=15)\n",
    "ax.set_ylabel(\"Purity\", fontsize=14)\n",
    "ax.set_xlabel(\"Files (n=151)\", fontsize=14, labelpad=10)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Hide x-axis tick labels (too many files)\n",
    "ax.set_xticks([])\n",
    "\n",
    "# Add mean purity reference line\n",
    "mean_purity = purity_df[\"Average Window Purity\"].mean()\n",
    "ax.axhline(mean_purity, color='crimson', linestyle='--', linewidth=1.5, label=f'Mean Purity: {mean_purity:.2f}')\n",
    "ax.legend(fontsize=12, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "75474187",
   "metadata": {
    "papermill": {
     "duration": 0.016943,
     "end_time": "2025-03-31T01:01:47.469803",
     "exception": false,
     "start_time": "2025-03-31T01:01:47.452860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualize accelaration (x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "id": "382f8523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T01:01:47.507788Z",
     "iopub.status.busy": "2025-03-31T01:01:47.507295Z",
     "iopub.status.idle": "2025-03-31T01:02:29.130896Z",
     "shell.execute_reply": "2025-03-31T01:02:29.129799Z"
    },
    "papermill": {
     "duration": 41.666369,
     "end_time": "2025-03-31T01:02:29.153509",
     "exception": false,
     "start_time": "2025-03-31T01:01:47.487140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "file_path = os.path.join(path, train_files[0])\n",
    "file_path = os.path.join(file_path, train_files[0])\n",
    "\n",
    "# The data of the first file\n",
    "day_data = pd.read_csv(file_path, index_col='time', parse_dates=['time'],\n",
    "                       dtype={'x': 'f4', 'y': 'f4', 'z': 'f4', 'annotation': 'string'})\n",
    "day_data = map_labels(day_data, label_dict, label_mapping)\n",
    "day_data = normalize(day_data, ['x', 'y', 'z'])\n",
    "\n",
    "# Create subplots for each axis\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 8), sharex=True)\n",
    "\n",
    "axs[0].plot(day_data['x'], color='blue')\n",
    "axs[0].set_ylabel(\"X Acceleration\")\n",
    "axs[0].set_title(\"X-axis\")\n",
    "\n",
    "axs[1].plot(day_data['y'], color='green')\n",
    "axs[1].set_ylabel(\"Y Acceleration\")\n",
    "axs[1].set_title(\"Y-axis\")\n",
    "\n",
    "axs[2].plot(day_data['z'], color='red')\n",
    "axs[2].set_ylabel(\"Z Acceleration\")\n",
    "axs[2].set_title(\"Z-axis\")\n",
    "axs[2].set_xlabel(\"Timestep\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3f2b1d9c",
   "metadata": {
    "papermill": {
     "duration": 0.019281,
     "end_time": "2025-03-31T01:02:29.192295",
     "exception": false,
     "start_time": "2025-03-31T01:02:29.173014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualize the labels of a day"
   ]
  },
  {
   "cell_type": "code",
   "id": "5c6a46d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T01:02:29.505926Z",
     "iopub.status.busy": "2025-03-31T01:02:29.505491Z",
     "iopub.status.idle": "2025-03-31T01:03:50.083892Z",
     "shell.execute_reply": "2025-03-31T01:03:50.082822Z"
    },
    "papermill": {
     "duration": 80.620511,
     "end_time": "2025-03-31T01:03:50.105174",
     "exception": false,
     "start_time": "2025-03-31T01:02:29.484663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "valid_labels = day_data['label'].dropna()\n",
    "\n",
    "# Get unique labels and their indices\n",
    "label_values, label_indices = np.unique(valid_labels, return_inverse=True)\n",
    "\n",
    "# Create a label array with -1 for missing labels\n",
    "label_array = np.full(day_data.shape[0], -1)\n",
    "label_array[valid_labels.index.map(lambda idx: day_data.index.get_loc(idx))] = label_indices\n",
    "\n",
    "# Resample if too many columns\n",
    "max_columns = 10000\n",
    "if label_array.shape[0] > max_columns:\n",
    "    factor = label_array.shape[0] // max_columns\n",
    "    label_array = label_array[::factor]\n",
    "\n",
    "label_matrix = label_array.reshape(1, -1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 2.5))\n",
    "im = ax.imshow(label_matrix, aspect='auto', cmap='tab10', vmin=0, vmax=len(label_values) - 1)\n",
    "\n",
    "ax.set_title(\"Activity Labels Over Time\", fontsize=14)\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel(\"Timestep\")\n",
    "\n",
    "cbar = fig.colorbar(im, ax=ax, orientation='vertical', ticks=np.arange(len(label_values)))\n",
    "cbar.ax.set_yticklabels(label_values)\n",
    "cbar.set_label(\"Activity\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5173716,
     "sourceId": 8639177,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10895.359139,
   "end_time": "2025-03-31T01:03:52.366487",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-30T22:02:17.007348",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
