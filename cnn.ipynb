{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 8639177,
     "sourceType": "datasetVersion",
     "datasetId": 5173716
    }
   ],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Imports",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.signal import resample\n",
    "\n",
    "from random import sample\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, BatchNormalization, LeakyReLU, Input, Add, GlobalAveragePooling1D"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-16T12:52:26.384838Z",
     "iopub.execute_input": "2025-03-16T12:52:26.385151Z",
     "iopub.status.idle": "2025-03-16T12:52:28.918002Z",
     "shell.execute_reply.started": "2025-03-16T12:52:26.385125Z",
     "shell.execute_reply": "2025-03-16T12:52:28.916830Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Verify GPU\nA simple check to see if we use the GPU or not.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if tensorflow.config.list_physical_devices('GPU'):\n    print(\"GPU device found, using MPS for acceleration.\")\nelse:\n    print(\"No GPU device found, falling back to CPU.\")",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Functions\n## map_labels\nThis function can be used to simplify the labels. With a given label dictionary, we can map the labels to a less specific label.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def map_labels(data, label_dict, label_mapping):\n    \"\"\"\n    Maps annotations in a dataset to their corresponding labels using a given mapping.\n\n    Args:\n        data (pd.DataFrame): A DataFrame containing an 'annotation' column with values to be mapped.\n        label_dict (dict): A dictionary containing mappings of annotation labels.\n                                Keys are label mapping names, and values are Pandas Series or DataFrames\n                                where the index represents annotation keys and values represent labels.\n        label_mapping (str): The key in `anno_label_dict` corresponding to the desired label mapping.\n\n    Returns:\n        pd.DataFrame: The input DataFrame with an added or updated 'label' column containing the mapped labels.\n    \"\"\"\n    data['label'] = (label_dict[label_mapping].reindex(data['annotation']).to_numpy())\n    return data",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-14T09:51:44.908063Z",
     "iopub.execute_input": "2025-03-14T09:51:44.908381Z",
     "iopub.status.idle": "2025-03-14T09:51:44.924223Z",
     "shell.execute_reply.started": "2025-03-14T09:51:44.908356Z",
     "shell.execute_reply": "2025-03-14T09:51:44.923382Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## normalize\nNormalize the data to make it better for generalization",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def normalize(data, feature_cols):\n    \"\"\"\n    Normalizes the specified feature columns of a DataFrame using Min-Max scaling.\n\n    Args:\n        data (pd.DataFrame): A DataFrame containing the features to be normalized.\n        feature_cols (list of str): List of column names in `data` to normalize.\n        \n    Returns:\n        pd.DataFrame: A new DataFrame with the specified columns normalized to the range [0, 1].\n        The original `data` DataFrame is modified in place.\n        \n    Notes:\n        - Min-Max normalization scales each feature column to the range [0, 1] based on \n          the minimum and maximum values of the column.\n        - This transformation is often used to prepare data for machine learning models \n          that are sensitive to feature magnitudes.\n    \"\"\"\n    scaler = MinMaxScaler()\n    data[feature_cols] = scaler.fit_transform(data[feature_cols])\n    return data",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-14T09:51:44.925232Z",
     "iopub.execute_input": "2025-03-14T09:51:44.925505Z",
     "iopub.status.idle": "2025-03-14T09:51:44.945841Z",
     "shell.execute_reply.started": "2025-03-14T09:51:44.925471Z",
     "shell.execute_reply": "2025-03-14T09:51:44.944991Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## extract_windows\nA function to create windows. We can also change the frequency of the windows by downsampling.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def extract_windows(data, winsize=90, input_frequency=100, output_frequency=64):\n    \"\"\"\n    Extracts sliding windows from time series data and labels for classification tasks.\n\n    Args:\n        data (pd.DataFrame): Time series DataFrame with 'x', 'y', 'z' (accelerometer data) and 'label'.\n                             Index should be a datetime-like index.\n        winsize (int): Window size in seconds.\n        input_frequency (int): Sampling frequency of input data in Hz.\n        output_frequency (int): Desired output frequency in Hz (must be a divisor of input_frequency).\n\n    Returns:\n        X (np.ndarray): Shape (n_samples, output_samples, 3), accelerometer windows.\n        Y (np.ndarray): Shape (n_samples,), most frequent label per window.\n    \"\"\"\n    # Calculate window size in samples and target output samples\n    window_samples = winsize * input_frequency\n    output_samples = winsize * output_frequency  # Expected downsampled length\n\n    X, Y = [], []\n\n    # Sliding window extraction\n    for start in range(0, len(data) - window_samples + 1, window_samples):\n        window = data.iloc[start:start + window_samples]\n\n        # Skip if missing values exist\n        if window.isna().any().any() or len(window) != window_samples:\n            continue\n\n        # Extract and resample accelerometer data\n        x = window[['x', 'y', 'z']].to_numpy()\n        x = resample(x, output_samples)  # Resample to match output frequency\n\n        # Extract the most frequent label (mode)\n        y = window['label'].mode().iloc[0]\n\n        X.append(x)\n        Y.append(y)\n\n    X = np.stack(X) if X else np.empty((0, output_samples, 3))\n    Y = np.array(Y) if Y else np.empty((0,))\n\n    return X, Y",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-14T09:51:44.946895Z",
     "iopub.execute_input": "2025-03-14T09:51:44.947302Z",
     "iopub.status.idle": "2025-03-14T09:51:44.963810Z",
     "shell.execute_reply.started": "2025-03-14T09:51:44.947268Z",
     "shell.execute_reply": "2025-03-14T09:51:44.963007Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## residual_block\nA function to create the residual blocks inside the model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def residual_block(inputs, filters, kernel_size=3, dropout_rate=0.5):\n    \"\"\"\n    Residual block with Conv1D layers, BatchNormalization, and LeakyReLU activations.\n    Includes a shortcut connection.\n    \"\"\"\n    x = Conv1D(filters=filters, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal')(inputs)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(negative_slope=0.1)(x)\n    x = Dropout(dropout_rate)(x)\n    \n    x = Conv1D(filters=filters, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal')(x)\n    x = BatchNormalization()(x)\n    \n    shortcut = inputs\n    if inputs.shape[-1] != filters:\n        shortcut = Conv1D(filters=filters, kernel_size=1, padding='same', kernel_initializer='he_normal')(inputs)\n    \n    x = Add()([x, shortcut])\n    x = LeakyReLU(negative_slope=0.1)(x)\n    return x",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-14T09:51:44.964753Z",
     "iopub.execute_input": "2025-03-14T09:51:44.965004Z",
     "iopub.status.idle": "2025-03-14T09:51:44.984437Z",
     "shell.execute_reply.started": "2025-03-14T09:51:44.964983Z",
     "shell.execute_reply": "2025-03-14T09:51:44.983450Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## create_model\nA function to create the model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model(\n",
    "    num_classes, \n",
    "    input_shape, \n",
    "    dropout_rate=0.5,\n",
    "    filters=128, \n",
    "    kernel_size=5, \n",
    "    residual_blocks=3,\n",
    "    learning_rate=3e-4\n",
    "):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Initial Convolution\n",
    "    x = Conv1D(filters=filters, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    x = MaxPooling1D(pool_size=3)(x)\n",
    "    \n",
    "    # First residual block set\n",
    "    for _ in range(residual_blocks):\n",
    "        x = residual_block(x, filters=filters)\n",
    "    x = MaxPooling1D(pool_size=3)(x)\n",
    "    \n",
    "    # Second residual block set\n",
    "    x = Conv1D(filters=filters * 2, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, filters=filters * 2)\n",
    "    x = MaxPooling1D(pool_size=5)(x)\n",
    "\n",
    "    # Third residual block set\n",
    "    for _ in range(residual_blocks):\n",
    "        x = residual_block(x, filters=filters * 2)\n",
    "    x = MaxPooling1D(pool_size=5)(x)\n",
    "\n",
    "    # Fourth residual block set (512 channels)\n",
    "    x = Conv1D(filters=filters * 4, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, filters=filters * 4)\n",
    "    x = MaxPooling1D(pool_size=5)(x)\n",
    "    \n",
    "    # Fully Connected Layer\n",
    "    x = Dense(filters * 8, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Final Layer\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Create and Compile Model\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate), \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-14T09:51:44.986492Z",
     "iopub.execute_input": "2025-03-14T09:51:44.986740Z",
     "iopub.status.idle": "2025-03-14T09:51:45.005731Z",
     "shell.execute_reply.started": "2025-03-14T09:51:44.986720Z",
     "shell.execute_reply": "2025-03-14T09:51:45.004764Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Print input files",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Dictionary of labels\nlabel_dict = pd.read_csv('/kaggle/input/capture-24-human-activity-recognition/capture24/annotation-label-dictionary.csv', index_col='annotation', dtype='string')\nprint(\"Annotation-Label Dictionary\")\nprint(label_dict)\n\n# Chosen label mapping\nlabel_mapping = \"label:Willetts2018\"\nprint(label_dict[label_mapping])\nprint()\n\n# Print files\nprint('Content of data/')\nprint(sorted(os.listdir('/kaggle/input/capture-24-human-activity-recognition/capture24')))\nprint()\n\n# All of the labels\nall_labels = list({*label_dict[label_mapping]})\nprint('All of the possible labels:')\nprint(all_labels)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-14T09:51:45.006769Z",
     "iopub.execute_input": "2025-03-14T09:51:45.007036Z",
     "iopub.status.idle": "2025-03-14T09:51:45.040877Z",
     "shell.execute_reply.started": "2025-03-14T09:51:45.007013Z",
     "shell.execute_reply": "2025-03-14T09:51:45.040138Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Training the model\n## Training parameters",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Path of the dataset\n",
    "path = '/kaggle/input/capture-24-human-activity-recognition/capture24/'\n",
    "\n",
    "# The files in the dataset\n",
    "file_list = sorted([f for f in os.listdir(path) if f.endswith('.csv') and f.startswith('P')])\n",
    "\n",
    "# Stopping criteria for testing\n",
    "counter = 0\n",
    "limit = 200\n",
    "limit = min(limit, len(file_list))\n",
    "print(\"Number of files used: \", limit)\n",
    "\n",
    "# Initialize label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Model initialized flag\n",
    "model_initialized = False\n",
    "\n",
    "# Number of files used purely for testing\n",
    "num_test_files = 25\n",
    "print(\"Number of test files: \", num_test_files)\n",
    "\n",
    "# Randomly select test files from the file list\n",
    "test_files = sample(file_list, num_test_files)\n",
    "\n",
    "# Remaining files used for training\n",
    "train_files = [f for f in file_list if f not in test_files]\n",
    "\n",
    "# Number of chunks to split the data into\n",
    "num_chunks = 4\n",
    "num_chunks = min(num_chunks, limit)\n",
    "print(\"Number of chunks used in training: \", num_chunks)\n",
    "\n",
    "# Size of each chunk\n",
    "chunk_size = len(train_files) // num_chunks\n",
    "# Remaining files that don't fit evenly into a chunk\n",
    "remaining_files = len(train_files) % num_chunks\n",
    "\n",
    "# Distribute remaining files across the chunks\n",
    "chunks = []\n",
    "for i in range(num_chunks):\n",
    "    # Give the extra files to the first few chunks\n",
    "    chunk = train_files[i * chunk_size: (i + 1) * chunk_size]\n",
    "    if i < remaining_files:\n",
    "        chunk.append(train_files[(num_chunks * chunk_size) + i])\n",
    "    chunks.append(chunk)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-14T09:51:45.042294Z",
     "iopub.execute_input": "2025-03-14T09:51:45.042694Z",
     "iopub.status.idle": "2025-03-14T09:51:45.051743Z",
     "shell.execute_reply.started": "2025-03-14T09:51:45.042652Z",
     "shell.execute_reply": "2025-03-14T09:51:45.050992Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Training on the chunks",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Iterate over the chunks\nfor chunk_idx, chunk in enumerate(chunks):\n    print(f\"Processing chunk {chunk_idx + 1}/{len(chunks)}\")\n\n    data_list = []\n    # Iterate over the files in the chunk\n    for file in chunk:\n        if counter >= limit:\n            break\n\n        counter += 1\n        file_path = os.path.join(path, file)\n        file_path = os.path.join(file_path, file)\n        data = pd.read_csv(file_path, index_col='time', parse_dates=['time'],\n                           dtype={'x': 'f4', 'y': 'f4', 'z': 'f4', 'annotation': 'string'})\n        \n        data = map_labels(data, label_dict, label_mapping)      \n        data = normalize(data, ['x','y','z'])\n        data_list.append(data)\n\n    X_chunk, Y_chunk = [], []\n\n    # Extract the windows from the data\n    for data in data_list:\n        X_, Y_ = extract_windows(data)\n        if X_ is None or Y_ is None or len(X_) == 0 or len(Y_) == 0:\n            print(f\"Warning: Empty window extraction in chunk {chunk_idx}.\")\n        else:\n            X_chunk.append(X_)\n            Y_chunk.append(Y_)\n\n    # A skip if the chunk is empty\n    if len(X_chunk) == 0 or len(Y_chunk) == 0:\n        print(f\"Error: No valid windows in chunk {chunk_idx}. Skipping...\")\n        continue\n\n    X_chunk = np.concatenate(X_chunk, axis=0)\n    Y_chunk = np.concatenate(Y_chunk, axis=0)\n\n    # If the model is not initialize it\n    if not model_initialized:\n        input_shape = (X_chunk.shape[1], X_chunk.shape[2])\n        print(f\"The input shape is: {input_shape}\")\n        print(f\"Number of windows: {X_chunk.shape[0]}\")\n        \n        model = create_model(num_classes=len(all_labels), input_shape=input_shape)\n        model_initialized = True\n\n    # Encode the labels\n    Y_chunk_encoded = label_encoder.transform(Y_chunk)\n\n    # Perform stratified train-validation split (90% train, 10% validation)\n    X_train, X_val, Y_train, Y_val = train_test_split(\n        X_chunk, Y_chunk_encoded, test_size=0.1, stratify=Y_chunk_encoded, random_state=42\n    )\n\n    # Fit the model with the labels\n    history = model.fit(\n        X_train, Y_train,\n        validation_data=(X_val, Y_val),\n        epochs=40,\n        batch_size=16,\n        verbose=0,\n    )\n\n    print(f\"Validation loss: {min(history.history['val_loss']):.4f}\")\n    print(f\"Validation accuracy: {max(history.history['val_accuracy']):.4f}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-14T09:51:45.052601Z",
     "iopub.execute_input": "2025-03-14T09:51:45.052918Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Testing the model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "data_list = []\n\n# Iterate over the test files\nfor test_idx, test_file in enumerate(test_files):\n    print(f\"Processing file {test_idx + 1}/{len(test_files)}\")\n\n    file_path = os.path.join(path, file)\n    file_path = os.path.join(file_path, file)\n    data = pd.read_csv(\n        file_path, index_col='time', parse_dates=['time'],\n        dtype={'x': 'f4', 'y': 'f4', 'z': 'f4', 'annotation': 'string'}\n    )\n\n    data = map_labels(data, label_dict, label_mapping)\n    data = normalize(data, ['x', 'y', 'z'])\n    data_list.append(data)\n\nX_test, Y_test = [], []\n\n# Extract the windows\nfor data in data_list:\n    X_, Y_ = extract_windows(data)\n    if X_ is None or Y_ is None or len(X_) == 0 or len(Y_) == 0:\n        print(f\"Warning: Empty window extraction in test.\")\n    else:\n        X_test.append(X_)\n        Y_test.append(Y_)\n\nX_test = np.concatenate(X_test, axis=0)\nY_test = np.concatenate(Y_test, axis=0)\n\n# Encode the labels\nY_test_encoded = label_encoder.transform(Y_test)\n\n# Make predictions\nY_pred = model.predict(X_test)\nY_pred = np.argmax(Y_pred, axis=1)\n\n# Decode predictions\nY_pred = label_encoder.inverse_transform(Y_pred)\n\n# Subset labels present in the test set\npresent_labels = np.unique(Y_test)\npresent_labels_encoded = label_encoder.transform(present_labels)\n\n# Calculate metrics\nacc = accuracy_score(Y_test, Y_pred)\nf1 = f1_score(Y_test, Y_pred, average='weighted', labels=present_labels)\nrecall = recall_score(Y_test, Y_pred, average='weighted', labels=present_labels)\nprecision = precision_score(Y_test, Y_pred, average='weighted', labels=present_labels)\n\n# Confusion matrix for present labels\ncm = confusion_matrix(Y_test, Y_pred, labels=present_labels, normalize='true')\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=present_labels)\ndisp.plot(cmap='Blues', values_format=\".2%\")\ndisp.ax_.set_title(\"Confusion Matrix (Percentage)\")\n\n# Print metrics\nprint(f\"  Accuracy: {acc:.4f}\")\nprint(f\"  F1 Score: {f1:.4f}\")\nprint(f\"  Recall: {recall:.4f}\")\nprint(f\"  Precision: {precision:.4f}\")\nprint(f\"  Confusion Matrix:\\n{cm}\")",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Save the model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "model.save(\"/kaggle/working/CNN.keras\")"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
